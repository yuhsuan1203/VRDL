{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import keras\nimport matplotlib.pyplot as plt\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout, Activation, Flatten\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\nfrom keras.optimizers import Adam, SGD\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.resnet50 import ResNet50\n\nprint(\"Import Keras\")","execution_count":2,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"},{"output_type":"stream","text":"Import Keras\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Specify Training Parameters\nbatchSize = 64               #-- Training Batch Size\nnum_classes = 13             #-- Number of classes\nnum_epochs = 35              #-- Number of epochs for training   \nlearningRate= 0.001          #-- Learning rate for the network\nlr_weight_decay = 0.95       #-- Learning weight decay. Reduce the learn rate by 0.95 after epoch","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\nx = model.output\nx = GlobalAveragePooling2D()(x)\n#x = Dense(1024, activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n#x = Dense(1024, activation='relu')(x) #dense layer 2\n#x = Dropout(0.5)(x)\nx = Dense(512, activation='relu')(x) #dense layer 3\n#x = Dense(256, activation='relu')(x) #dense layer 4\nx = Dropout(0.33)(x)\nx = Dense(128, activation='relu')(x) #dense layer 5\nx = Dropout(0.33)(x)\n#x = Dense(64, activation='relu')(x) #dense layer 6\n#x = Dense(32, activation='relu')(x)\npreds = Dense(num_classes, activation='softmax')(x) #final layer with softmax activation\n\nmodel2 = Model(inputs=model.input, outputs=preds)\nfor layer in model2.layers[:20]:\n    layer.trainable=False\nfor layer in model2.layers[20:]:\n    layer.trainable=True\n    \nmodel2.summary()","execution_count":4,"outputs":[{"output_type":"stream","text":"Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58892288/58889256 [==============================] - 1s 0us/step\nModel: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, 224, 224, 3)       0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n_________________________________________________________________\nglobal_average_pooling2d_1 ( (None, 512)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               262656    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 128)               65664     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 128)               0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 13)                1677      \n=================================================================\nTotal params: 15,044,685\nTrainable params: 329,997\nNon-trainable params: 14,714,688\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3 = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\nx3 = model3.output\nx3 = GlobalAveragePooling2D()(x3)\nx3 = Dense(1024, activation='relu')(x3) #dense layer 3\nx3 = Dropout(0.33)(x3)\nx3 = Dense(512, activation='relu')(x3) #dense layer 3\nx3 = Dropout(0.33)(x3)\nx3 = Dense(128, activation='relu')(x3) #dense layer 5\nx3 = Dropout(0.33)(x3)\npreds3 = Dense(num_classes, activation='softmax')(x3) #final layer with softmax activation\n\nmodel4 = Model(inputs=model3.input, outputs=preds3)\nfor layer in model4.layers[:175]:\n    layer.trainable=False\nfor layer in model4.layers[175:]:\n    layer.trainable=True\n    \nmodel4.summary()","execution_count":5,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n","name":"stderr"},{"output_type":"stream","text":"Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94658560/94653016 [==============================] - 2s 0us/step\nModel: \"model_2\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n__________________________________________________________________________________________________\nconv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_2[0][0]                    \n__________________________________________________________________________________________________\nconv1 (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n__________________________________________________________________________________________________\nbn_conv1 (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      \n__________________________________________________________________________________________________\nactivation_1 (Activation)       (None, 112, 112, 64) 0           bn_conv1[0][0]                   \n__________________________________________________________________________________________________\npool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_1[0][0]               \n__________________________________________________________________________________________________\nmax_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n__________________________________________________________________________________________________\nres2a_branch2a (Conv2D)         (None, 56, 56, 64)   4160        max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nbn2a_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_2 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2a[0][0]              \n__________________________________________________________________________________________________\nres2a_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_2[0][0]               \n__________________________________________________________________________________________________\nbn2a_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2a_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_3 (Activation)       (None, 56, 56, 64)   0           bn2a_branch2b[0][0]              \n__________________________________________________________________________________________________\nres2a_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_3[0][0]               \n__________________________________________________________________________________________________\nres2a_branch1 (Conv2D)          (None, 56, 56, 256)  16640       max_pooling2d_1[0][0]            \n__________________________________________________________________________________________________\nbn2a_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2a_branch2c[0][0]             \n__________________________________________________________________________________________________\nbn2a_branch1 (BatchNormalizatio (None, 56, 56, 256)  1024        res2a_branch1[0][0]              \n__________________________________________________________________________________________________\nadd_1 (Add)                     (None, 56, 56, 256)  0           bn2a_branch2c[0][0]              \n                                                                 bn2a_branch1[0][0]               \n__________________________________________________________________________________________________\nactivation_4 (Activation)       (None, 56, 56, 256)  0           add_1[0][0]                      \n__________________________________________________________________________________________________\nres2b_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_4[0][0]               \n__________________________________________________________________________________________________\nbn2b_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_5 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2a[0][0]              \n__________________________________________________________________________________________________\nres2b_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_5[0][0]               \n__________________________________________________________________________________________________\nbn2b_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2b_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_6 (Activation)       (None, 56, 56, 64)   0           bn2b_branch2b[0][0]              \n__________________________________________________________________________________________________\nres2b_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_6[0][0]               \n__________________________________________________________________________________________________\nbn2b_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2b_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_2 (Add)                     (None, 56, 56, 256)  0           bn2b_branch2c[0][0]              \n                                                                 activation_4[0][0]               \n__________________________________________________________________________________________________\nactivation_7 (Activation)       (None, 56, 56, 256)  0           add_2[0][0]                      \n__________________________________________________________________________________________________\nres2c_branch2a (Conv2D)         (None, 56, 56, 64)   16448       activation_7[0][0]               \n__________________________________________________________________________________________________\nbn2c_branch2a (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_8 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2a[0][0]              \n__________________________________________________________________________________________________\nres2c_branch2b (Conv2D)         (None, 56, 56, 64)   36928       activation_8[0][0]               \n__________________________________________________________________________________________________\nbn2c_branch2b (BatchNormalizati (None, 56, 56, 64)   256         res2c_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_9 (Activation)       (None, 56, 56, 64)   0           bn2c_branch2b[0][0]              \n__________________________________________________________________________________________________\nres2c_branch2c (Conv2D)         (None, 56, 56, 256)  16640       activation_9[0][0]               \n__________________________________________________________________________________________________\nbn2c_branch2c (BatchNormalizati (None, 56, 56, 256)  1024        res2c_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_3 (Add)                     (None, 56, 56, 256)  0           bn2c_branch2c[0][0]              \n                                                                 activation_7[0][0]               \n__________________________________________________________________________________________________\nactivation_10 (Activation)      (None, 56, 56, 256)  0           add_3[0][0]                      \n__________________________________________________________________________________________________\nres3a_branch2a (Conv2D)         (None, 28, 28, 128)  32896       activation_10[0][0]              \n__________________________________________________________________________________________________\nbn3a_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_11 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2a[0][0]              \n__________________________________________________________________________________________________\nres3a_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_11[0][0]              \n__________________________________________________________________________________________________\nbn3a_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3a_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_12 (Activation)      (None, 28, 28, 128)  0           bn3a_branch2b[0][0]              \n__________________________________________________________________________________________________\nres3a_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_12[0][0]              \n__________________________________________________________________________________________________\nres3a_branch1 (Conv2D)          (None, 28, 28, 512)  131584      activation_10[0][0]              \n__________________________________________________________________________________________________\nbn3a_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3a_branch2c[0][0]             \n__________________________________________________________________________________________________\nbn3a_branch1 (BatchNormalizatio (None, 28, 28, 512)  2048        res3a_branch1[0][0]              \n__________________________________________________________________________________________________\nadd_4 (Add)                     (None, 28, 28, 512)  0           bn3a_branch2c[0][0]              \n                                                                 bn3a_branch1[0][0]               \n__________________________________________________________________________________________________\nactivation_13 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n__________________________________________________________________________________________________\nres3b_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_13[0][0]              \n__________________________________________________________________________________________________\nbn3b_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_14 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2a[0][0]              \n__________________________________________________________________________________________________\nres3b_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_14[0][0]              \n__________________________________________________________________________________________________\nbn3b_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3b_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_15 (Activation)      (None, 28, 28, 128)  0           bn3b_branch2b[0][0]              \n__________________________________________________________________________________________________\nres3b_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_15[0][0]              \n__________________________________________________________________________________________________\nbn3b_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3b_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_5 (Add)                     (None, 28, 28, 512)  0           bn3b_branch2c[0][0]              \n                                                                 activation_13[0][0]              \n__________________________________________________________________________________________________\nactivation_16 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n__________________________________________________________________________________________________\nres3c_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_16[0][0]              \n__________________________________________________________________________________________________\nbn3c_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_17 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2a[0][0]              \n__________________________________________________________________________________________________\nres3c_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_17[0][0]              \n__________________________________________________________________________________________________\nbn3c_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3c_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_18 (Activation)      (None, 28, 28, 128)  0           bn3c_branch2b[0][0]              \n__________________________________________________________________________________________________\nres3c_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_18[0][0]              \n__________________________________________________________________________________________________\nbn3c_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3c_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_6 (Add)                     (None, 28, 28, 512)  0           bn3c_branch2c[0][0]              \n                                                                 activation_16[0][0]              \n__________________________________________________________________________________________________\nactivation_19 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n__________________________________________________________________________________________________\nres3d_branch2a (Conv2D)         (None, 28, 28, 128)  65664       activation_19[0][0]              \n__________________________________________________________________________________________________\nbn3d_branch2a (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_20 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2a[0][0]              \n__________________________________________________________________________________________________\nres3d_branch2b (Conv2D)         (None, 28, 28, 128)  147584      activation_20[0][0]              \n__________________________________________________________________________________________________\nbn3d_branch2b (BatchNormalizati (None, 28, 28, 128)  512         res3d_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_21 (Activation)      (None, 28, 28, 128)  0           bn3d_branch2b[0][0]              \n__________________________________________________________________________________________________\nres3d_branch2c (Conv2D)         (None, 28, 28, 512)  66048       activation_21[0][0]              \n__________________________________________________________________________________________________\nbn3d_branch2c (BatchNormalizati (None, 28, 28, 512)  2048        res3d_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_7 (Add)                     (None, 28, 28, 512)  0           bn3d_branch2c[0][0]              \n                                                                 activation_19[0][0]              \n__________________________________________________________________________________________________\nactivation_22 (Activation)      (None, 28, 28, 512)  0           add_7[0][0]                      \n__________________________________________________________________________________________________\nres4a_branch2a (Conv2D)         (None, 14, 14, 256)  131328      activation_22[0][0]              \n__________________________________________________________________________________________________\nbn4a_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_23 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2a[0][0]              \n__________________________________________________________________________________________________\nres4a_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_23[0][0]              \n__________________________________________________________________________________________________\nbn4a_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4a_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_24 (Activation)      (None, 14, 14, 256)  0           bn4a_branch2b[0][0]              \n__________________________________________________________________________________________________\nres4a_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_24[0][0]              \n__________________________________________________________________________________________________\nres4a_branch1 (Conv2D)          (None, 14, 14, 1024) 525312      activation_22[0][0]              \n__________________________________________________________________________________________________\nbn4a_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4a_branch2c[0][0]             \n__________________________________________________________________________________________________\nbn4a_branch1 (BatchNormalizatio (None, 14, 14, 1024) 4096        res4a_branch1[0][0]              \n__________________________________________________________________________________________________\nadd_8 (Add)                     (None, 14, 14, 1024) 0           bn4a_branch2c[0][0]              \n                                                                 bn4a_branch1[0][0]               \n__________________________________________________________________________________________________\nactivation_25 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n__________________________________________________________________________________________________\nres4b_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_25[0][0]              \n__________________________________________________________________________________________________\nbn4b_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_26 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2a[0][0]              \n__________________________________________________________________________________________________\nres4b_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_26[0][0]              \n__________________________________________________________________________________________________\nbn4b_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4b_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_27 (Activation)      (None, 14, 14, 256)  0           bn4b_branch2b[0][0]              \n__________________________________________________________________________________________________\nres4b_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_27[0][0]              \n__________________________________________________________________________________________________\nbn4b_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4b_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_9 (Add)                     (None, 14, 14, 1024) 0           bn4b_branch2c[0][0]              \n                                                                 activation_25[0][0]              \n__________________________________________________________________________________________________\nactivation_28 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n__________________________________________________________________________________________________\nres4c_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_28[0][0]              \n__________________________________________________________________________________________________\nbn4c_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_29 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2a[0][0]              \n__________________________________________________________________________________________________\nres4c_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_29[0][0]              \n__________________________________________________________________________________________________\nbn4c_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4c_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_30 (Activation)      (None, 14, 14, 256)  0           bn4c_branch2b[0][0]              \n__________________________________________________________________________________________________\nres4c_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_30[0][0]              \n__________________________________________________________________________________________________\nbn4c_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4c_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_10 (Add)                    (None, 14, 14, 1024) 0           bn4c_branch2c[0][0]              \n                                                                 activation_28[0][0]              \n__________________________________________________________________________________________________\nactivation_31 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n__________________________________________________________________________________________________\nres4d_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_31[0][0]              \n__________________________________________________________________________________________________\nbn4d_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_32 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2a[0][0]              \n__________________________________________________________________________________________________\nres4d_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_32[0][0]              \n__________________________________________________________________________________________________\nbn4d_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4d_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_33 (Activation)      (None, 14, 14, 256)  0           bn4d_branch2b[0][0]              \n__________________________________________________________________________________________________\nres4d_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_33[0][0]              \n__________________________________________________________________________________________________\nbn4d_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4d_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_11 (Add)                    (None, 14, 14, 1024) 0           bn4d_branch2c[0][0]              \n                                                                 activation_31[0][0]              \n__________________________________________________________________________________________________\nactivation_34 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n__________________________________________________________________________________________________\nres4e_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_34[0][0]              \n__________________________________________________________________________________________________\nbn4e_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_35 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2a[0][0]              \n__________________________________________________________________________________________________\nres4e_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_35[0][0]              \n__________________________________________________________________________________________________\nbn4e_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4e_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_36 (Activation)      (None, 14, 14, 256)  0           bn4e_branch2b[0][0]              \n__________________________________________________________________________________________________\nres4e_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_36[0][0]              \n__________________________________________________________________________________________________\nbn4e_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4e_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_12 (Add)                    (None, 14, 14, 1024) 0           bn4e_branch2c[0][0]              \n                                                                 activation_34[0][0]              \n__________________________________________________________________________________________________\nactivation_37 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n__________________________________________________________________________________________________\nres4f_branch2a (Conv2D)         (None, 14, 14, 256)  262400      activation_37[0][0]              \n__________________________________________________________________________________________________\nbn4f_branch2a (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_38 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2a[0][0]              \n__________________________________________________________________________________________________\nres4f_branch2b (Conv2D)         (None, 14, 14, 256)  590080      activation_38[0][0]              \n__________________________________________________________________________________________________\nbn4f_branch2b (BatchNormalizati (None, 14, 14, 256)  1024        res4f_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_39 (Activation)      (None, 14, 14, 256)  0           bn4f_branch2b[0][0]              \n__________________________________________________________________________________________________\nres4f_branch2c (Conv2D)         (None, 14, 14, 1024) 263168      activation_39[0][0]              \n__________________________________________________________________________________________________\nbn4f_branch2c (BatchNormalizati (None, 14, 14, 1024) 4096        res4f_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_13 (Add)                    (None, 14, 14, 1024) 0           bn4f_branch2c[0][0]              \n                                                                 activation_37[0][0]              \n__________________________________________________________________________________________________\nactivation_40 (Activation)      (None, 14, 14, 1024) 0           add_13[0][0]                     \n__________________________________________________________________________________________________\nres5a_branch2a (Conv2D)         (None, 7, 7, 512)    524800      activation_40[0][0]              \n__________________________________________________________________________________________________\nbn5a_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_41 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2a[0][0]              \n__________________________________________________________________________________________________\nres5a_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_41[0][0]              \n__________________________________________________________________________________________________\nbn5a_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5a_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_42 (Activation)      (None, 7, 7, 512)    0           bn5a_branch2b[0][0]              \n__________________________________________________________________________________________________\nres5a_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_42[0][0]              \n__________________________________________________________________________________________________\nres5a_branch1 (Conv2D)          (None, 7, 7, 2048)   2099200     activation_40[0][0]              \n__________________________________________________________________________________________________\nbn5a_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5a_branch2c[0][0]             \n__________________________________________________________________________________________________\nbn5a_branch1 (BatchNormalizatio (None, 7, 7, 2048)   8192        res5a_branch1[0][0]              \n__________________________________________________________________________________________________\nadd_14 (Add)                    (None, 7, 7, 2048)   0           bn5a_branch2c[0][0]              \n                                                                 bn5a_branch1[0][0]               \n__________________________________________________________________________________________________\nactivation_43 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n__________________________________________________________________________________________________\nres5b_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_43[0][0]              \n__________________________________________________________________________________________________\nbn5b_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_44 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2a[0][0]              \n__________________________________________________________________________________________________\nres5b_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_44[0][0]              \n__________________________________________________________________________________________________\nbn5b_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5b_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_45 (Activation)      (None, 7, 7, 512)    0           bn5b_branch2b[0][0]              \n__________________________________________________________________________________________________\nres5b_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_45[0][0]              \n__________________________________________________________________________________________________\nbn5b_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5b_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_15 (Add)                    (None, 7, 7, 2048)   0           bn5b_branch2c[0][0]              \n                                                                 activation_43[0][0]              \n__________________________________________________________________________________________________\nactivation_46 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n__________________________________________________________________________________________________\nres5c_branch2a (Conv2D)         (None, 7, 7, 512)    1049088     activation_46[0][0]              \n__________________________________________________________________________________________________\nbn5c_branch2a (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2a[0][0]             \n__________________________________________________________________________________________________\nactivation_47 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2a[0][0]              \n__________________________________________________________________________________________________\nres5c_branch2b (Conv2D)         (None, 7, 7, 512)    2359808     activation_47[0][0]              \n__________________________________________________________________________________________________\nbn5c_branch2b (BatchNormalizati (None, 7, 7, 512)    2048        res5c_branch2b[0][0]             \n__________________________________________________________________________________________________\nactivation_48 (Activation)      (None, 7, 7, 512)    0           bn5c_branch2b[0][0]              \n__________________________________________________________________________________________________\nres5c_branch2c (Conv2D)         (None, 7, 7, 2048)   1050624     activation_48[0][0]              \n__________________________________________________________________________________________________\nbn5c_branch2c (BatchNormalizati (None, 7, 7, 2048)   8192        res5c_branch2c[0][0]             \n__________________________________________________________________________________________________\nadd_16 (Add)                    (None, 7, 7, 2048)   0           bn5c_branch2c[0][0]              \n                                                                 activation_46[0][0]              \n__________________________________________________________________________________________________\nactivation_49 (Activation)      (None, 7, 7, 2048)   0           add_16[0][0]                     \n__________________________________________________________________________________________________\nglobal_average_pooling2d_2 (Glo (None, 2048)         0           activation_49[0][0]              \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_2[0][0] \n__________________________________________________________________________________________________\ndropout_3 (Dropout)             (None, 1024)         0           dense_4[0][0]                    \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (None, 512)          524800      dropout_3[0][0]                  \n__________________________________________________________________________________________________\ndropout_4 (Dropout)             (None, 512)          0           dense_5[0][0]                    \n__________________________________________________________________________________________________\ndense_6 (Dense)                 (None, 128)          65664       dropout_4[0][0]                  \n__________________________________________________________________________________________________\ndropout_5 (Dropout)             (None, 128)          0           dense_6[0][0]                    \n__________________________________________________________________________________________________\ndense_7 (Dense)                 (None, 13)           1677        dropout_5[0][0]                  \n==================================================================================================\nTotal params: 26,278,029\nTrainable params: 2,690,317\nNon-trainable params: 23,587,712\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model3 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\nx3 = model3.output\nx3 = GlobalAveragePooling2D()(x3)\nx3 = Dense(512, activation='relu')(x3) #dense layer 3\nx3 = Dropout(0.35)(x3)\nx3 = Dense(128, activation='relu')(x3) #dense layer 5\nx3 = Dropout(0.35)(x3)\npreds3 = Dense(num_classes, activation='softmax')(x3) #final layer with softmax activation\n\nmodel4 = Model(inputs=model3.input, outputs=preds3)\nfor layer in model4.layers[:20]:\n    layer.trainable=False\nfor layer in model4.layers[20:]:\n    layer.trainable=True\n    \nmodel4.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model5 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\nx5 = model5.output\nx5 = GlobalAveragePooling2D()(x5)\nx5 = Dense(512, activation='relu')(x5) #dense layer 3\nx5 = Dropout(0.3)(x5)\nx5 = Dense(128, activation='relu')(x5) #dense layer 5\nx5 = Dropout(0.3)(x5)\npreds5 = Dense(num_classes, activation='softmax')(x5) #final layer with softmax activation\n\nmodel6 = Model(inputs=model5.input, outputs=preds5)\nfor layer in model6.layers[:20]:\n    layer.trainable=False\nfor layer in model6.layers[20:]:\n    layer.trainable=True\n    \nmodel6.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.imagenet_utils import preprocess_input, decode_predictions\ntrain_datagen=ImageDataGenerator(preprocessing_function=preprocess_input, zoom_range=0.12, horizontal_flip=True) #, validation_split=0.13) #included in our dependencies\n\ntrain_generator=train_datagen.flow_from_directory('/kaggle/input/cs-ioc5008-hw1/dataset/dataset/train/', # this is where you specify the path to the main data folder\n                                                 target_size=(224, 224),\n                                                 batch_size=batchSize,\n                                                 class_mode='categorical',\n                                                 shuffle=True) #,\n#                                                 subset=\"training\")\n\n#validation_generator=train_datagen.flow_from_directory('/kaggle/input/cs-ioc5008-hw1/dataset/dataset/train/', # this is where you specify the path to the main data folder\n#                                                 target_size=(224, 224),\n#                                                 batch_size=batchSize,\n#                                                 class_mode='categorical',\n#                                                 shuffle=False,\n#                                                 subset=\"validation\")","execution_count":6,"outputs":[{"output_type":"stream","text":"Found 2819 images belonging to 13 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_map = train_generator.class_indices\nlabel_map = dict((v,k) for k,v in label_map.items())\nfor i in range(len(label_map)):\n    print(\"class\" + \" {:>2}\".format(str(i+1)) + \": \" + label_map[i])\n    ","execution_count":7,"outputs":[{"output_type":"stream","text":"class  1: bedroom\nclass  2: coast\nclass  3: forest\nclass  4: highway\nclass  5: insidecity\nclass  6: kitchen\nclass  7: livingroom\nclass  8: mountain\nclass  9: office\nclass 10: opencountry\nclass 11: street\nclass 12: suburb\nclass 13: tallbuilding\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sgd = SGD(lr=learningRate, decay=lr_weight_decay)\nadam_optimizer = Adam(lr=learningRate, decay=lr_weight_decay)\n\nmodel2.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel4.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n#model6.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n# Adam optimizer\n# loss function will be categorical cross entropy\n# evaluation metric will be accuracy\n\nstep_size_train=train_generator.n//train_generator.batch_size\n#step_size_validation=validation_generator.n//validation_generator.batch_size\nmodel2.fit_generator(generator=train_generator, \n                     steps_per_epoch=step_size_train, \n#                     validation_data=validation_generator, \n#                     validation_steps=step_size_validation, \n                     epochs=num_epochs)\nmodel4.fit_generator(generator=train_generator, \n                     steps_per_epoch=step_size_train, \n#                     validation_data=validation_generator, \n#                     validation_steps=step_size_validation, \n                     epochs=num_epochs)\n#model6.fit_generator(generator=train_generator, \n#                     steps_per_epoch=step_size_train, \n#                     validation_data=validation_generator, \n#                     validation_steps=step_size_validation, \n#                     epochs=num_epochs)","execution_count":10,"outputs":[{"output_type":"stream","text":"Epoch 1/35\n44/44 [==============================] - 40s 920ms/step - loss: 1.5602 - accuracy: 0.5358\nEpoch 2/35\n44/44 [==============================] - 35s 785ms/step - loss: 0.6174 - accuracy: 0.7989\nEpoch 3/35\n44/44 [==============================] - 34s 783ms/step - loss: 0.4853 - accuracy: 0.8374\nEpoch 4/35\n44/44 [==============================] - 34s 774ms/step - loss: 0.3820 - accuracy: 0.8679\nEpoch 5/35\n44/44 [==============================] - 35s 794ms/step - loss: 0.2982 - accuracy: 0.8868\nEpoch 6/35\n44/44 [==============================] - 34s 780ms/step - loss: 0.3175 - accuracy: 0.8915\nEpoch 7/35\n44/44 [==============================] - 34s 779ms/step - loss: 0.3076 - accuracy: 0.8922\nEpoch 8/35\n44/44 [==============================] - 34s 772ms/step - loss: 0.2792 - accuracy: 0.9034\nEpoch 9/35\n44/44 [==============================] - 34s 776ms/step - loss: 0.2144 - accuracy: 0.9169\nEpoch 10/35\n44/44 [==============================] - 34s 774ms/step - loss: 0.2234 - accuracy: 0.9285\nEpoch 11/35\n44/44 [==============================] - 34s 776ms/step - loss: 0.2032 - accuracy: 0.9307\nEpoch 12/35\n44/44 [==============================] - 34s 780ms/step - loss: 0.1879 - accuracy: 0.9314\nEpoch 13/35\n44/44 [==============================] - 35s 801ms/step - loss: 0.1819 - accuracy: 0.9371\nEpoch 14/35\n44/44 [==============================] - 35s 806ms/step - loss: 0.1836 - accuracy: 0.9426\nEpoch 15/35\n44/44 [==============================] - 35s 794ms/step - loss: 0.1715 - accuracy: 0.9416\nEpoch 16/35\n44/44 [==============================] - 34s 769ms/step - loss: 0.1573 - accuracy: 0.9484\nEpoch 17/35\n44/44 [==============================] - 34s 783ms/step - loss: 0.1300 - accuracy: 0.9554\nEpoch 18/35\n44/44 [==============================] - 35s 801ms/step - loss: 0.1296 - accuracy: 0.9567\nEpoch 19/35\n44/44 [==============================] - 34s 768ms/step - loss: 0.1109 - accuracy: 0.9581\nEpoch 20/35\n44/44 [==============================] - 35s 801ms/step - loss: 0.1038 - accuracy: 0.9602\nEpoch 21/35\n44/44 [==============================] - 35s 791ms/step - loss: 0.1196 - accuracy: 0.9586\nEpoch 22/35\n44/44 [==============================] - 36s 810ms/step - loss: 0.1246 - accuracy: 0.9572\nEpoch 23/35\n44/44 [==============================] - 34s 767ms/step - loss: 0.1190 - accuracy: 0.9607\nEpoch 24/35\n44/44 [==============================] - 35s 785ms/step - loss: 0.1440 - accuracy: 0.9481\nEpoch 25/35\n44/44 [==============================] - 35s 798ms/step - loss: 0.0922 - accuracy: 0.9680\nEpoch 26/35\n44/44 [==============================] - 34s 778ms/step - loss: 0.1295 - accuracy: 0.9557\nEpoch 27/35\n44/44 [==============================] - 35s 785ms/step - loss: 0.1086 - accuracy: 0.9593\nEpoch 28/35\n44/44 [==============================] - 34s 764ms/step - loss: 0.0840 - accuracy: 0.9718\nEpoch 29/35\n44/44 [==============================] - 35s 803ms/step - loss: 0.0859 - accuracy: 0.9695\nEpoch 30/35\n44/44 [==============================] - 35s 786ms/step - loss: 0.1434 - accuracy: 0.9579\nEpoch 31/35\n44/44 [==============================] - 35s 804ms/step - loss: 0.0901 - accuracy: 0.9684\nEpoch 32/35\n44/44 [==============================] - 34s 769ms/step - loss: 0.0716 - accuracy: 0.9744\nEpoch 33/35\n44/44 [==============================] - 35s 791ms/step - loss: 0.0725 - accuracy: 0.9757\nEpoch 34/35\n44/44 [==============================] - 34s 784ms/step - loss: 0.0801 - accuracy: 0.9753\nEpoch 35/35\n44/44 [==============================] - 36s 809ms/step - loss: 0.0580 - accuracy: 0.9808\nEpoch 1/35\n44/44 [==============================] - 36s 814ms/step - loss: 1.6665 - accuracy: 0.4508\nEpoch 2/35\n44/44 [==============================] - 35s 798ms/step - loss: 0.6655 - accuracy: 0.7637\nEpoch 3/35\n44/44 [==============================] - 35s 802ms/step - loss: 0.6175 - accuracy: 0.8171\nEpoch 4/35\n44/44 [==============================] - 35s 800ms/step - loss: 0.4340 - accuracy: 0.8584\nEpoch 5/35\n44/44 [==============================] - 36s 815ms/step - loss: 0.3872 - accuracy: 0.8730\nEpoch 6/35\n44/44 [==============================] - 35s 800ms/step - loss: 0.3730 - accuracy: 0.8795\nEpoch 7/35\n44/44 [==============================] - 35s 803ms/step - loss: 0.4058 - accuracy: 0.8744\nEpoch 8/35\n44/44 [==============================] - 35s 805ms/step - loss: 0.3886 - accuracy: 0.8704\nEpoch 9/35\n44/44 [==============================] - 35s 805ms/step - loss: 0.2846 - accuracy: 0.9045\nEpoch 10/35\n44/44 [==============================] - 35s 804ms/step - loss: 0.2314 - accuracy: 0.9336\nEpoch 11/35\n44/44 [==============================] - 35s 801ms/step - loss: 0.3741 - accuracy: 0.8857\nEpoch 12/35\n44/44 [==============================] - 36s 817ms/step - loss: 0.2369 - accuracy: 0.9126\nEpoch 13/35\n44/44 [==============================] - 36s 822ms/step - loss: 0.2169 - accuracy: 0.9252\nEpoch 14/35\n44/44 [==============================] - 35s 790ms/step - loss: 0.3168 - accuracy: 0.9065\nEpoch 15/35\n44/44 [==============================] - 36s 825ms/step - loss: 0.2027 - accuracy: 0.9407\nEpoch 16/35\n44/44 [==============================] - 36s 809ms/step - loss: 0.2018 - accuracy: 0.9394\nEpoch 17/35\n44/44 [==============================] - 35s 789ms/step - loss: 0.2390 - accuracy: 0.9332\nEpoch 18/35\n44/44 [==============================] - 37s 832ms/step - loss: 0.1699 - accuracy: 0.9439\nEpoch 19/35\n44/44 [==============================] - 35s 792ms/step - loss: 0.2100 - accuracy: 0.9350\nEpoch 20/35\n44/44 [==============================] - 36s 824ms/step - loss: 0.1816 - accuracy: 0.9446\nEpoch 21/35\n44/44 [==============================] - 35s 789ms/step - loss: 0.2069 - accuracy: 0.9480\nEpoch 22/35\n44/44 [==============================] - 36s 822ms/step - loss: 0.2525 - accuracy: 0.9212\nEpoch 23/35\n44/44 [==============================] - 35s 805ms/step - loss: 0.1462 - accuracy: 0.9499\nEpoch 24/35\n44/44 [==============================] - 36s 808ms/step - loss: 0.1610 - accuracy: 0.9564\nEpoch 25/35\n44/44 [==============================] - 35s 805ms/step - loss: 0.2257 - accuracy: 0.9296\nEpoch 26/35\n44/44 [==============================] - 36s 809ms/step - loss: 0.1567 - accuracy: 0.9506\nEpoch 27/35\n44/44 [==============================] - 37s 832ms/step - loss: 0.1218 - accuracy: 0.9585\nEpoch 28/35\n44/44 [==============================] - 36s 811ms/step - loss: 0.1189 - accuracy: 0.9659\nEpoch 29/35\n44/44 [==============================] - 35s 788ms/step - loss: 0.1822 - accuracy: 0.9599\nEpoch 30/35\n44/44 [==============================] - 37s 841ms/step - loss: 0.1549 - accuracy: 0.9464\nEpoch 31/35\n44/44 [==============================] - 35s 786ms/step - loss: 0.1395 - accuracy: 0.9540\nEpoch 32/35\n44/44 [==============================] - 36s 826ms/step - loss: 0.1081 - accuracy: 0.9613\nEpoch 33/35\n44/44 [==============================] - 36s 808ms/step - loss: 0.1708 - accuracy: 0.9535\nEpoch 34/35\n44/44 [==============================] - 34s 783ms/step - loss: 0.2712 - accuracy: 0.9395\nEpoch 35/35\n44/44 [==============================] - 36s 824ms/step - loss: 0.1667 - accuracy: 0.9450\n","name":"stdout"},{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7fce0bca1e48>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\n\ntest_data_name = []\ntest_data = []\n\nfor dirname, _, filenames in os.walk('/kaggle/input/cs-ioc5008-hw1/dataset/dataset/test'):\n    for filename in filenames:\n        test_data_name.append(filename)\n        image = cv2.imread(os.path.join(dirname, filename))\n        test_data.append(image)\n        \nprint(\"Number of test data =\", len(test_data))","execution_count":11,"outputs":[{"output_type":"stream","text":"Number of test data = 1040\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def processing(image_data):\n    #img = [data[123], data[1054], data[156]]\n    #print(\"Original size:\", img[1].shape)\n    #print(training_label[1054])\n    #original = img[1]\n    #display_one(original)\n    \n    height = 224\n    width = 224\n    dim = (width, height)\n    res_img = []\n    \n    for i in range(len(image_data)):\n        res = cv2.resize(image_data[i], dim, interpolation=cv2.INTER_LINEAR)\n        res_img.append(res)\n    \n    return res_img\n\ntest_data_reshape = processing(test_data)\n\nprint(test_data_reshape[0].shape)","execution_count":12,"outputs":[{"output_type":"stream","text":"(224, 224, 3)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(test_data_reshape)):\n    test_data_reshape[i] = preprocess_input(test_data_reshape[i])","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for i in range(len(test_data_reshape)):\n#    test_data_reshape[i] = (test_data_reshape[i] - 128.0) / 128.0\n   \nfor i in range(len(test_data_reshape)):\n    test_data_reshape[i] = test_data_reshape[i].reshape(-1, 224, 224, 3)\ncount = 0\nprint(\"id,label\")\n\nfor i in range(len(test_data_reshape)):\n    name_arr = test_data_name[i].split('.')\n    name = name_arr[0]\n    answer2 = model2.predict(test_data_reshape[i])\n    answer4 = model4.predict(test_data_reshape[i])\n    #answer6 = model6.predict(test_data_reshape[i])\n    #answer = [answer2[i] + answer4[i] + answer6[i] for i in range(len(answer2))] \n    #print(name + \",\" + label_map[np.argmax(answer)])\n    if np.argmax(answer2) != np.argmax(answer4):\n        count += 1\n        print(name+\": \"+\" vgg16:\"+\" {:>15}\".format(label_map[np.argmax(answer2)])+\" {:>10}\".format(str(answer2[0][np.argmax(answer2)]))+\n                      \", resnet:\"+\" {:>15}\".format(label_map[np.argmax(answer4)])+\" {:>10}\".format(str(answer4[0][np.argmax(answer4)])))\n        \nprint(count)\n    #index = np.argmax(answer4)\n    #prob1 = answer4[0][index]\n    #ans1 = label_map[index]\n    #answer4[0][index] = -1\n    #\n    #index = np.argmax(answer4)\n    #prob2 = answer4[0][index]\n    #ans2 = label_map[index]\n    #\n    #if abs(prob2-prob1) < 0.2:\n    #    print(name+\": \"+ans1+\",\"+str(prob1)+\"   \"+ans2+\",\"+str(prob2))","execution_count":16,"outputs":[{"output_type":"stream","text":"id,label\nimage_0653:  vgg16:         bedroom  0.9969651, resnet:      livingroom  0.7164869\nimage_0447:  vgg16:    tallbuilding 0.99962544, resnet:      insidecity  0.9483726\nimage_0888:  vgg16:          forest 0.99623126, resnet:     opencountry  0.7020697\nimage_0718:  vgg16:           coast  0.8626452, resnet:         highway 0.99563664\nimage_0661:  vgg16:      livingroom 0.90069205, resnet:          office   0.978868\nimage_0681:  vgg16:           coast  0.9417446, resnet:     opencountry 0.65744543\nimage_0516:  vgg16:          office   0.999977, resnet:      livingroom 0.73107725\nimage_0667:  vgg16:           coast 0.99286836, resnet:     opencountry 0.64434904\nimage_0641:  vgg16:         kitchen 0.71618015, resnet:          office 0.99925834\nimage_0270:  vgg16:         kitchen  0.9997439, resnet:      livingroom 0.87329084\nimage_0407:  vgg16:      insidecity 0.99999905, resnet:          street 0.66619295\nimage_0258:  vgg16:         kitchen   0.784721, resnet:      livingroom  0.8881721\nimage_0824:  vgg16:         kitchen 0.97372943, resnet:      livingroom  0.8729552\nimage_0595:  vgg16:         bedroom 0.54387814, resnet:      livingroom  0.5271891\nimage_0564:  vgg16:      livingroom 0.86377436, resnet:         bedroom 0.74239284\nimage_0323:  vgg16:      livingroom 0.76965183, resnet:         bedroom  0.5047832\nimage_0931:  vgg16:      insidecity  0.9894023, resnet:          street  0.9971732\nimage_0099:  vgg16:         bedroom 0.99972636, resnet:      livingroom 0.52871144\nimage_0008:  vgg16:           coast  0.9936813, resnet:     opencountry 0.60109293\nimage_0184:  vgg16:          forest  0.9997688, resnet:     opencountry  0.9998504\nimage_0338:  vgg16:          forest 0.97679013, resnet:     opencountry  0.7828557\nimage_0363:  vgg16:     opencountry   0.998569, resnet:           coast  0.6458106\nimage_0650:  vgg16:        mountain  0.9999999, resnet:     opencountry 0.83579004\nimage_0962:  vgg16:        mountain  0.9740283, resnet:         highway   0.665076\nimage_0061:  vgg16:      livingroom  0.6990575, resnet:         bedroom 0.53922665\nimage_0787:  vgg16:           coast  0.9997427, resnet:     opencountry  0.9555195\nimage_0460:  vgg16:          forest 0.99958843, resnet:     opencountry 0.99999833\nimage_0216:  vgg16:          forest  0.9999995, resnet:     opencountry 0.99979967\nimage_0959:  vgg16:        mountain   0.995529, resnet:     opencountry 0.95201826\nimage_0140:  vgg16:         bedroom 0.99644667, resnet:      livingroom 0.74228853\nimage_0380:  vgg16:     opencountry  0.9923793, resnet:         highway  0.8369127\nimage_0156:  vgg16:    tallbuilding  0.9947082, resnet:          street   0.987061\nimage_0475:  vgg16:        mountain    0.99998, resnet:     opencountry  0.5281504\nimage_0240:  vgg16:          forest 0.94438344, resnet:     opencountry  0.9998871\nimage_0265:  vgg16:      insidecity   0.843393, resnet:          suburb 0.99999976\nimage_0092:  vgg16:         kitchen  0.9694783, resnet:      livingroom  0.5695338\nimage_0659:  vgg16:           coast  0.8360017, resnet:     opencountry 0.99979955\nimage_0635:  vgg16:         kitchen  0.8682664, resnet:          office 0.94080037\nimage_0852:  vgg16:          forest  0.6138664, resnet:     opencountry 0.99906343\nimage_0556:  vgg16:           coast  0.8312532, resnet:     opencountry  0.5556519\nimage_0445:  vgg16:      livingroom 0.68937474, resnet:         bedroom 0.50811136\nimage_0856:  vgg16:         kitchen  0.9997038, resnet:      livingroom  0.5745172\nimage_0179:  vgg16:      insidecity 0.99762183, resnet:         highway   0.753607\nimage_0163:  vgg16:        mountain 0.66162306, resnet:     opencountry 0.99258834\nimage_0834:  vgg16:      livingroom 0.93863404, resnet:         bedroom 0.53732926\nimage_0794:  vgg16:         kitchen 0.98886275, resnet:         bedroom 0.66978174\nimage_0012:  vgg16:        mountain        1.0, resnet:     opencountry  0.9948679\nimage_0135:  vgg16:         bedroom  0.5302187, resnet:      livingroom 0.92360497\nimage_0417:  vgg16:          forest  0.9999999, resnet:     opencountry 0.87463903\nimage_0206:  vgg16:     opencountry  0.9767619, resnet:           coast  0.8281426\nimage_0268:  vgg16:        mountain  0.9070144, resnet:     opencountry  0.9655964\nimage_0944:  vgg16:      livingroom 0.88986117, resnet:         kitchen  0.5721456\nimage_0386:  vgg16:          office  0.6868758, resnet:         bedroom  0.6648793\nimage_0453:  vgg16:        mountain 0.93241215, resnet:     opencountry 0.94377625\nimage_0147:  vgg16:        mountain 0.98329586, resnet:     opencountry 0.99349135\nimage_0129:  vgg16:          forest        1.0, resnet:     opencountry 0.92822766\nimage_0937:  vgg16:      livingroom  0.8807621, resnet:         bedroom  0.5814218\nimage_0589:  vgg16:           coast 0.99889225, resnet:     opencountry  0.7831488\nimage_0277:  vgg16:           coast 0.99970704, resnet:     opencountry 0.98982084\nimage_0282:  vgg16:          forest 0.84195876, resnet:     opencountry  0.9975151\nimage_0463:  vgg16:          forest 0.56912196, resnet:     opencountry  0.9996728\nimage_0915:  vgg16:          forest  0.9986473, resnet:     opencountry 0.95310384\nimage_0513:  vgg16:         bedroom 0.61410785, resnet:      livingroom  0.6520808\nimage_0402:  vgg16:          forest 0.99998426, resnet:     opencountry  0.9999925\nimage_0292:  vgg16:          forest  0.9638872, resnet:     opencountry  0.7842784\nimage_0237:  vgg16:          forest 0.93067247, resnet:     opencountry 0.98746663\nimage_0011:  vgg16:      livingroom  0.9518236, resnet:         bedroom 0.65656996\nimage_0139:  vgg16:          forest  0.9998864, resnet:     opencountry  0.9028183\nimage_0682:  vgg16:         kitchen  0.9637805, resnet:      livingroom 0.89409465\nimage_0482:  vgg16:         bedroom  0.9880657, resnet:          suburb  0.4969876\nimage_0527:  vgg16:         kitchen  0.9999604, resnet:          street 0.55880654\nimage_0280:  vgg16:          forest 0.67648387, resnet:     opencountry  0.9999114\nimage_0580:  vgg16:          forest 0.99997866, resnet:     opencountry  0.5879924\nimage_0266:  vgg16:         bedroom 0.80301577, resnet:      livingroom  0.9177188\nimage_0801:  vgg16:        mountain  0.9999175, resnet:     opencountry 0.99374217\nimage_0871:  vgg16:         bedroom 0.99918085, resnet:      livingroom  0.8310805\nimage_0766:  vgg16:      livingroom 0.94701034, resnet:         highway  0.9921361\nimage_0226:  vgg16:     opencountry  0.9999294, resnet:           coast  0.8496352\nimage_0238:  vgg16:      livingroom 0.76928246, resnet:         bedroom  0.8939022\nimage_0421:  vgg16:         kitchen 0.99998605, resnet:          office   0.825123\nimage_0082:  vgg16:         bedroom  0.8196689, resnet:      livingroom 0.97132707\nimage_1006:  vgg16:      livingroom  0.9769142, resnet:          street  0.7279797\nimage_0053:  vgg16:        mountain  0.9999801, resnet:     opencountry 0.91550255\nimage_0716:  vgg16:      insidecity 0.87471586, resnet:          street  0.9848936\nimage_0972:  vgg16:          office 0.99972993, resnet:         kitchen  0.9819518\nimage_0948:  vgg16:      livingroom  0.6806081, resnet:         bedroom 0.81685865\nimage_0907:  vgg16:           coast  0.9833356, resnet:          forest  0.5251899\nimage_0570:  vgg16:        mountain   0.988564, resnet:         highway 0.88408005\nimage_0920:  vgg16:        mountain 0.96465755, resnet:     opencountry 0.99573743\nimage_0149:  vgg16:          forest  0.9222405, resnet:     opencountry  0.5583267\nimage_0256:  vgg16:          forest  0.9838531, resnet:     opencountry 0.99002564\nimage_0923:  vgg16:         kitchen  0.9237691, resnet:      livingroom 0.98848593\nimage_0170:  vgg16:        mountain 0.99999905, resnet:     opencountry 0.72652483\nimage_0390:  vgg16:          forest  0.9305872, resnet:     opencountry  0.9999981\nimage_0122:  vgg16:         kitchen    0.97823, resnet:      livingroom  0.7374783\nimage_0026:  vgg16:          forest 0.99945396, resnet:     opencountry 0.98531973\nimage_0828:  vgg16:         kitchen  0.9745782, resnet:      livingroom  0.6860288\nimage_0848:  vgg16:         bedroom 0.54437494, resnet:         kitchen  0.9984345\nimage_0741:  vgg16:         bedroom  0.7707407, resnet:      livingroom 0.61044383\n","name":"stdout"},{"output_type":"stream","text":"image_0697:  vgg16:    tallbuilding 0.99999964, resnet:          street 0.99999857\nimage_0942:  vgg16:        mountain  0.9999969, resnet:     opencountry 0.76496917\nimage_0472:  vgg16:          street   0.789064, resnet:         highway  0.9999989\nimage_0384:  vgg16:          forest  0.8102247, resnet:     opencountry  0.8724708\nimage_0821:  vgg16:      insidecity  0.6494779, resnet:         highway 0.99984336\nimage_0439:  vgg16:     opencountry  0.9670088, resnet:           coast 0.99816895\nimage_0466:  vgg16:         bedroom 0.88542944, resnet:         kitchen 0.73451716\nimage_0190:  vgg16:      livingroom  0.9227136, resnet:          street  0.9998301\nimage_0355:  vgg16:    tallbuilding  0.8345595, resnet:      insidecity 0.78978217\nimage_0696:  vgg16:        mountain  0.9995353, resnet:     opencountry 0.99232024\nimage_0686:  vgg16:         bedroom 0.95819354, resnet:      livingroom  0.9823137\nimage_0155:  vgg16:        mountain  0.9891794, resnet:     opencountry  0.7391272\nimage_0430:  vgg16:          forest 0.99922144, resnet:     opencountry 0.98302585\nimage_0624:  vgg16:      livingroom 0.98977506, resnet:         bedroom 0.81565136\nimage_0891:  vgg16:        mountain 0.99963355, resnet:         highway  0.9455393\nimage_0646:  vgg16:         bedroom  0.9841031, resnet:      livingroom  0.5176581\nimage_0672:  vgg16:      insidecity  0.9999852, resnet:          street 0.85364544\nimage_0644:  vgg16:         kitchen 0.99936396, resnet:      livingroom   0.885316\nimage_0221:  vgg16:     opencountry  0.9987035, resnet:           coast  0.7655766\nimage_0840:  vgg16:         bedroom  0.9890332, resnet:      livingroom    0.76645\nimage_0740:  vgg16:     opencountry  0.9904957, resnet:           coast  0.9997782\nimage_0857:  vgg16:         bedroom  0.7744199, resnet:         kitchen  0.8121211\nimage_0869:  vgg16:          forest 0.99999225, resnet:     opencountry  0.9988945\nimage_0091:  vgg16:      insidecity   0.689993, resnet:          street  0.9999956\nimage_1038:  vgg16:          forest 0.99984944, resnet:     opencountry  0.9908688\nimage_0605:  vgg16:      insidecity  0.9131535, resnet:          street  0.9999987\nimage_0707:  vgg16:          forest  0.9983734, resnet:         highway 0.58975554\nimage_0690:  vgg16:          forest 0.99950147, resnet:     opencountry 0.49353525\nimage_0377:  vgg16:          forest  0.9834773, resnet:     opencountry   0.966108\nimage_1008:  vgg16:      insidecity  0.9982529, resnet:          street 0.99999976\nimage_0636:  vgg16:     opencountry  0.9845546, resnet:           coast 0.66485316\nimage_0928:  vgg16:        mountain 0.99997795, resnet:     opencountry  0.6237472\nimage_0831:  vgg16:      livingroom 0.99951375, resnet:         bedroom  0.9122729\nimage_0111:  vgg16:          forest 0.99764353, resnet:     opencountry 0.82369006\nimage_0281:  vgg16:     opencountry  0.5145688, resnet:           coast  0.7224319\nimage_0849:  vgg16:      insidecity 0.99303114, resnet:          street 0.99986136\nimage_0064:  vgg16:           coast  0.9978108, resnet:     opencountry  0.9467589\nimage_0036:  vgg16:      livingroom 0.95206374, resnet:          street  0.9999963\nimage_0229:  vgg16:          suburb   0.999864, resnet:          street 0.72770643\nimage_0215:  vgg16:          forest 0.99989426, resnet:     opencountry   0.797288\nimage_0032:  vgg16:         bedroom  0.5600635, resnet:      livingroom  0.9582947\nimage_0429:  vgg16:      livingroom  0.9351382, resnet:          office  0.8999617\nimage_0649:  vgg16:      insidecity 0.99999964, resnet:          street 0.64195126\nimage_0368:  vgg16:         kitchen  0.6138978, resnet:         bedroom  0.9474003\nimage_0726:  vgg16:          forest 0.99996555, resnet:     opencountry 0.99487644\nimage_0863:  vgg16:          forest   0.921055, resnet:     opencountry  0.7858627\nimage_0751:  vgg16:        mountain  0.9611126, resnet:     opencountry  0.9999734\nimage_0312:  vgg16:          forest  0.9999994, resnet:     opencountry  0.9961737\nimage_0890:  vgg16:     opencountry  0.4663745, resnet:      insidecity  0.9914665\nimage_0557:  vgg16:          forest 0.91917855, resnet:     opencountry  0.4884305\nimage_0065:  vgg16:      livingroom  0.5030199, resnet:          office  0.9999528\nimage_0964:  vgg16:         bedroom 0.99592006, resnet:      livingroom  0.9036019\nimage_0488:  vgg16:        mountain 0.99571395, resnet:     opencountry  0.9801104\nimage_0904:  vgg16:    tallbuilding  0.9980274, resnet:          street  0.9998253\nimage_0297:  vgg16:     opencountry 0.54097694, resnet:           coast 0.99998415\nimage_0261:  vgg16:    tallbuilding  0.8950323, resnet:      insidecity  0.9992355\nimage_0634:  vgg16:        mountain 0.99990034, resnet:     opencountry 0.81852347\nimage_0276:  vgg16:      livingroom 0.97953826, resnet:         bedroom 0.52165705\nimage_0991:  vgg16:     opencountry  0.8081805, resnet:           coast 0.99991596\nimage_0660:  vgg16:      livingroom 0.47867265, resnet:          office 0.96073854\n159\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}